{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340d58d7-8fbf-4bda-9fa3-51839902943e",
   "metadata": {},
   "source": [
    "This experiment uses the lr2_data.txt dataset, which contains a simulated house area and price data.\n",
    "To obtain the dataset, see the Lab Environment Setup.\n",
    "\n",
    "\n",
    "Step 1 Import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d21e57b-9227-495f-a5b5-5519f5fae4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b5e44f-9cd2-4562-9a29-bde118dd701e",
   "metadata": {},
   "source": [
    "Step 2  Define the function for calculating gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19653084-ed04-4874-aada-a84e275057a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradient(X, theta, y):\n",
    "    sample_count = X.shape[0]\n",
    "    #Calculate the gradient based on the matrix 1/mΣ(((h(x^i)-y^i))x_j^i)\n",
    "    return (1 / sample_count)*X.T.dot(X.dot(theta)-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2f6be-01c4-4942-b280-8711e973ed4e",
   "metadata": {},
   "source": [
    "Step 3 Define the function for reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8876b10c-11be-45c6-8007-a4cc5887481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(file_path):\n",
    "    orig_data = np.loadtxt(file_path,skiprows=1)#Ignore the title in the first row of the dataset.\n",
    "    cols =orig_data.shape[1]\n",
    "    return(orig_data, orig_data[:, :cols-1], orig_data[:, cols-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d6629-ce0c-4848-8af5-09faf1cf37f2",
   "metadata": {},
   "source": [
    "Step 4 Define the function for intializing parameters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f7257f8-d81a-4a87-8361-5757c074ddf8",
   "metadata": {},
   "source": [
    "#Initialize the θ array.\n",
    "def init_theta(feature_count):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ac70c-c342-400b-8223-c7b4bd2985e9",
   "metadata": {},
   "source": [
    "Step 5 Define the function for implementing the gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa15755b-0feb-4ccc-aa36-369945431698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descending(X, y, theta, alpha):\n",
    "    Jthetas = [] #Record the change trend of the cost function J(θ) to confirm the gradient descent is correc.\n",
    "    #Calculate the loss function , which is equal to the square of the difference between the actual value and the predicted value: (y^i-h(c^i))\n",
    "    Jtheta = (X.dot(theta)-y).T.dot(X.dot(theta)-y)\n",
    "    index = 0\n",
    "    gradient = generate_gradient(X, theta, y) #Calculate the gradient.\n",
    "    while not np.all((np.absolute(gradient) <= 1e-5)): #End the calculation when the gradient is less than 0.00001.\n",
    "        theta = theta - alpha * gradient\n",
    "        gradient = generate_gradient(X, theta, y) #Calculate the new gradient.\n",
    "        #Calculate the loss function, which is equal to the square of the difference between the actualvalue anf the predicted value: (y^i-h(x^i))^2\n",
    "        Jtheta = (X.dot(theta)-y).T.dot(X.dot(theta)-y)\n",
    "        if(index+1)%10==0:\n",
    "            Jthetas.append((index, Jtheta[0])) #Record the result every 10 calculations\n",
    "        index+=1\n",
    "    return theta, Jthetas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b5bb6-d62b-4943-8052-5b683ca95dd4",
   "metadata": {},
   "source": [
    "Step 6 Define the function for visualizing the change curve of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ca3f1d-b089-4ff0-814d-98b37f5ee35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the loss function change curve.\n",
    "def showJtheta(diff_value):\n",
    "    p_x = []\n",
    "    p_y = []\n",
    "    for (index, sum) in diff_value:\n",
    "        p_x.append(index)\n",
    "        p_y.append(sum)\n",
    "    plt.plot(p_x, p_y, color='b')\n",
    "    plt.xlabel(\"steps\")\n",
    "    plt.ylabel(\"loss function\")\n",
    "    plt.title('step-loss function curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aebf6cc-20da-4fdb-b779-011d0f79ce7a",
   "metadata": {},
   "source": [
    "Step 7 Define the function for visualizin data points and the fitted curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19cb193-4dd0-40b6-a2bf-976e3db03e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the actual data points and the fitted curve\n",
    "def showlinecurve(theta, sample_training_set):\n",
    "    x, y = sample_training_set[:, 1], sample_training_set[:,2]\n",
    "    z = theta[0] + theta[1] * x\n",
    "    plt.scatter(x, y, color='b', marker='x', label=\"Sample data\")\n",
    "    plt.plot(x, z, 'r', color='r', label=\"regression curve\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('linear regression curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550eab4f-cd89-4eaa-b3eb-d0016dc13130",
   "metadata": {},
   "source": [
    "Step 8 Plot the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a35eefc-fe6a-43f9-8d13-6b448500db10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_theta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Initialize θ.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m theta \u001b[38;5;241m=\u001b[39m \u001b[43minit_theta\u001b[49m(feature_count)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Obtain the final parameter θ and cost\u001b[39;00m\n\u001b[0;32m     10\u001b[0m result_theta, Jthetas \u001b[38;5;241m=\u001b[39m gradient_descending(training_x, y, theta, alpha)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'init_theta' is not defined"
     ]
    }
   ],
   "source": [
    "#Read the datset\n",
    "training_data_include_y, training_x, y = get_training_data(\"../Practicals-Dataset/02/lr2_data.txt\")\n",
    "#Obtain he number of samples and features respectively.\n",
    "sample_count, feature_count = training_x.shape\n",
    "#Define the learning step α.\n",
    "alpha = 0.01\n",
    "#Initialize θ.\n",
    "theta = init_theta(feature_count)\n",
    "#Obtain the final parameter θ and cost\n",
    "result_theta, Jthetas = gradient_descending(training_x, y, theta, alpha)\n",
    "#Display the parameter.\n",
    "print(\"w:{}\".format(result_theta[0][0]), \"b:{}\".format(result_theta[1][0]))\n",
    "showJtheta(Jthetas)\n",
    "showlinecurve(result_theta, training_data_include_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d45540-218d-465a-ad9a-87a8947604e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
